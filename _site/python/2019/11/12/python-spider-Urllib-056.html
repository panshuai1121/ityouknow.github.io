<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Favicon Icon -->
    <link rel="shortcut icon" type="image/x-icon" href="/assets/images/favicon.ico">

    <title> 第56天：urllib 包基本使用 - 潘帅的博客 </title>
    <meta name="keywords" content="ityouknow,Spring,Spring Boot,Spring Cloud,MongoDB,Jvm,Docker,生活故事,架构,大数据,一线,FastDFS,开发者,编程,代码,开源,IT网站,Developer,Programmer,Coder,Geek,IT技术博客,Java,Python,">
    <meta name="description"
          content="&lt;p&gt;urllib 是一个 python 内置包，不需要额外安装即可使用，包里面包含了以下几个用来处理 url 的模块：&lt;/p&gt;
">

    <link rel="canonical" href="https://panshuai1121.github.io/pages/panshuai1121/python/2019/11/12/python-spider-Urllib-056.html">
    <link rel="alternate" type="application/rss+xml" title="潘帅的博客" href="https://panshuai1121.github.io/pages/panshuai1121/feed.xml">

    <!-- Third-Party CSS -->
    <link rel="stylesheet" href="/bower_components/bootstrap/dist/css/bootstrap.min.css?v=1">
    <link rel="stylesheet" href="/bower_components/octicons/octicons/octicons.css?v=1">
    <link rel="stylesheet" href="/bower_components/hover/css/hover-min.css">
    <link rel="stylesheet" href="/bower_components/primer-markdown/dist/user-content.min.css">
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="stylesheet" href="/assets/css/gitalk.css">

    

    <!-- My CSS -->
    <link rel="stylesheet" href="/assets/css/common.css">

    <!-- CSS set in page -->
    

    <!-- CSS set in layout -->
    
    <link rel="stylesheet" href="/assets/css/sidebar-post-nav.css">
    

    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css">

    <script type="text/javascript" src="/bower_components/jquery/dist/jquery.min.js"></script>
    <script type="text/javascript" src="/bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="/assets/js/lock.js?v=1"></script>
</head>


    <body>

    <header class="site-header">
    <div class="site-header-topbar">
        <div class="container">
            <div class="topbar-menu">
                
                <div class="item">
                    <a href="/it.html"
                       target="_self"
                       title="深度">
                        深度
                    </a>
                </div>
                
                <div class="item">
                    <a href="/life.html"
                       target="_self"
                       title="故事">
                        故事
                    </a>
                </div>
                
                <div class="item">
                    <a href="/arch.html"
                       target="_self"
                       title="架构">
                        架构
                    </a>
                </div>
                
                <div class="item">
                    <a href="/link.html"
                       target="_self"
                       title="友链">
                        友链
                    </a>
                </div>
                
            </div>
        </div>
    </div>
    <div class="container">
        <a id="site-header-brand" href="/" title="潘帅的博客">
            <span class="octicon octicon-smiley"></span>
            潘帅的博客
        </a>
        <nav class="site-header-nav" role="navigation">
            
            <div class=" site-header-nav-item hvr-underline-from-center">
                <a href="/"
                   target=""
                   title="Home">
                    Home
                </a>
                
            </div>
            
            <div class=" site-header-nav-item hvr-underline-from-center">
                <a href="/spring-boot.html"
                   target="_self"
                   title="Spring Boot">
                    Spring Boot
                </a>
                
                <ul class="submenu">
                    
                    <li><a href="/spring-boot.html" 
                           target=""
                     >Spring Boot</a></li>
                    
                    <li><a href="/spring-cloud.html" 
                           target=""
                     >Spring Cloud</a></li>
                    
                </ul>
                
            </div>
            
            <div class=" site-header-nav-item hvr-underline-from-center">
                <a href="/php.html"
                   target="_self"
                   title="PHP">
                    PHP
                </a>
                
            </div>
            
            <div class=" site-header-nav-item hvr-underline-from-center">
                <a href="/python.html"
                   target=""
                   title="Python">
                    Python
                </a>
                
                <ul class="submenu">
                    
                    <li><a href="/python.html" 
                           target=""
                     >Python 教程</a></li>
                    
                    <li><a href="http://www.justdopython.com" 
                           target="_blank"
                     >Python 技术</a></li>
                    
                </ul>
                
            </div>
            
            <div class=" site-header-nav-item hvr-underline-from-center">
                <a href="/archives.html"
                   target="_self"
                   title="Archives">
                    Archives
                </a>
                
            </div>
            
        </nav>
    </div>
</header>


        <div class="content">
            <section class="jumbotron geopattern" data-pattern-id="第56天：urllib 包基本使用">
    <div class="container">
        <div id="jumbotron-meta-info">        
            <h1>第56天：urllib 包基本使用</h1>
            <span class="meta-info">
                
                
                <span class="octicon octicon-calendar"></span> 2019/11/12
                
            </span>
        </div>
    </div>
</section>
<script>
    $(document).ready(function(){

        $('.geopattern').each(function(){
            $(this).geopattern($(this).data('pattern-id'));
        });

    });
</script>
<article class="post container " itemscope itemtype="http://schema.org/BlogPosting">

    <div class="row">

        
        <div class="col-md-9 markdown-body">

            <p>urllib 是一个 python 内置包，不需要额外安装即可使用，包里面包含了以下几个用来处理 url 的模块：</p>

<ul>
  <li>urllib.request，用来打开和读取 url，意思就是可以用它来模拟发送请求，就像在浏览器里输入网址然后敲击回车一样，获取网页响应内容。</li>
  <li>urllib.error，用来处理 urllib.request 引起的异常，保证程序的正常执行。</li>
  <li>urllib.parse，用来解析 url，可以对 url 进行拆分、合并等。</li>
  <li>urllib.robotparse，用来解析 robots.txt 文件，判断网站是否能够进行爬取。</li>
</ul>

<p>掌握以上四个模块，你就能对网站进行简单的爬虫操作，下面我们逐个介绍。</p>

<!--more-->

<h2 id="1-urllibrequest-模块">1 urllib.request 模块</h2>

<p>urllib.request 模块定义了以下几个函数。</p>

<h3 id="11-urllibrequesturlopenurl-datanone-timeout--cafilenone-capathnone-cadefaultfalse-contextnone">1.1 urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)</h3>

<p>该函数主要用于模拟网站请求，返回一个 HTTPResponse 类型的对象。</p>

<h4 id="111-urlopen-函数中参数定义">1.1.1 urlopen 函数中参数定义</h4>

<ul>
  <li>url，必选参数，是一个 str 字符串或者 Request 对象(后面会介绍)。</li>
  <li>data，bytes 类型的可选参数，如果传递的是字典型数据，可以用 urllib.parse.urlencode() 进行编码，返回 str 字符串，再将 str 转换成 bytes 字节流。如果传递 data 参数，urlopen 将使用 HTTP POST 方式请求，否则为 HTTP GET 请求。</li>
  <li>timeout，可选参数，设置超时时间(未设置时使用全局默认超时时间)，以秒为单位计时，如果 urlopen 请求超出了设置时间还未得到响应则抛出异常。</li>
  <li>cafile 和 capath，可选参数，在 HTTPS 连接请求时指定已认证的 CA 证书以及证书路径。</li>
  <li>cadefault，一般可忽略该参数。</li>
  <li>context，ssl.SSLContext 类型的可选参数，用来指定 SSL 设置。</li>
</ul>

<h4 id="112-urlopen-函数返回类型">1.1.2 urlopen 函数返回类型</h4>

<p>urlopen 函数请求返回一个 HTTPResponse 响应上下文，或者请求异常抛出 URLError 协议错误，一般有如下属性：</p>

<ul>
  <li>geturl()，返回检索的 url，通常用于判定是否进行了重定向。</li>
  <li>info()，返回网页的头信息。</li>
  <li>getcode()，返回 HTTPResponse 响应的状态码。</li>
</ul>

<h4 id="113-urlopen-函数的应用实例">1.1.3 urlopen 函数的应用实例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 创建一个 HTTP GET 请求，输出响应上下文
from urllib.request import urlopen
response = urlopen("http://www.python.org")
print(response.read()) 
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 创建一个 HTTP POST 请求，输出响应上下文
from urllib.request import urlopen
from urllib.parse import urlencode
data = {'kw' : 'python'}
data = bytes(urlencode(data), encoding = 'utf-8')
response = urlopen("https://fanyi.baidu.com/sug", data)
print(response.read().decode('unicode_escape'))
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 创建一个 HTTP GET 请求，设置超时时间为0.1s
import urllib.request
import urllib.error
try:
    response=urllib.request.urlopen('http://www.python.org',timeout=0.1)
    print(response.read()) 
except urllib.error.URLError as e:
    print(e.reason)
</code></pre></div></div>

<h3 id="12-urllibrequestrequesturl-datanone-headers-origin_req_hostnone-unverifiablefalse-methodnone">1.2 urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)</h3>

<p>该函数主要用于构造一个 url，返回一个 urllib.request.Request 对象。</p>

<h4 id="121-request-函数中参数定义">1.2.1 Request 函数中参数定义</h4>

<ul>
  <li>url，必选参数，请求的 url 地址。</li>
  <li>data，bytes 类型的可选参数。</li>
  <li>headers，字典类型，有些 HTTP 服务器仅允许来自浏览器的请求，因此通过 headers 来模拟浏览器对 url 的访问，比如模拟谷歌浏览器时使用的 headers：”Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36”。可以通过调用 add_header() 来添加 headers 信息。</li>
  <li>origin_req_host，请求方的 host 名称或者 IP 地址。</li>
  <li>unverifiable，表示这个请求是否无法验证，默认为 False。比如请求一张图片，如果没有权限获取图片那它的值就是 true。</li>
  <li>method，是一个字符串，用来指示请求使用的方法，如：GET,POST,PUT 等，默认是 GET 请求。</li>
</ul>

<h4 id="122-request-函数返回类型">1.2.2 Request 函数返回类型</h4>

<p>与 urlopen 函数请求返回一样，一般返回一个 HTTPResponse 响应上下文。</p>

<h4 id="123-request-函数的应用实例">1.2.3 Request 函数的应用实例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 采用 HTTP GET 请求的方法模拟谷歌浏览器访问网站，输出响应上下文
from urllib import request,parse
url = 'http://www.python.org'
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'
}
req = request.Request(url, headers = headers, method = 'GET')
response = request.urlopen(req) 
print(response.read())
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 采用 HTTP POST 请求的方法模拟谷歌浏览器访问网站，输出响应上下文
from urllib import request
from urllib import parse
url = 'https://fanyi.baidu.com/sug'
data = {'kw' : 'python'}
data = bytes(parse.urlencode(data), encoding = 'utf-8')
headers = {
    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'
}
req = request.Request(url, data, headers, method = 'POST')
response = request.urlopen(req) 
print(response.read().decode('unicode_escape'))
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 创建一个 HTTP GET 请求，通过 add_header 添加一个 UserAgent
import urllib.request
import random
url = 'http://www.python.org'
headerUserAgentList = ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36',
'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:69.0) Gecko/20100101 Firefox/69.0']
randomHeaderUserAgent = random.choice(headerUserAgentList) # 随机选取一个 UserAgent
req = urllib.request.Request(url) 
req.add_header('User-Agent', randomHeaderUserAgent) # 添加 UserAgent
response=urllib.request.urlopen(req)
print(req.get_header('User-agent'))
print(req.headers) # 打印请求的 header 信息
</code></pre></div></div>

<h2 id="2-urlliberror-模块">2 urllib.error 模块</h2>

<p>urllib.error 模块定义了由 urllib.request 模块引发的异常，异常主要包含 URLError 和 HTTPError。</p>

<h3 id="21-urlliberrorurlerror-异常">2.1 urllib.error.URLError 异常</h3>

<p>URLError 类继承自 OSError 类，是 error 异常模块的基类，由request模块产生的异常都可以通过捕获这个类来处理。URLError 只有一个属性 reason，即返回错误的原因。</p>

<p>应用实例：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 在请求连接时候捕获网址错误引发的异常
from urllib import request, error
try:
    response = request.urlopen('https://www,baidu,com')
except error.URLError as e:
    print(e.reason)
</code></pre></div></div>

<h3 id="22-urlliberrorhttperror-异常">2.2 urllib.error.HTTPError 异常</h3>

<p>HTTPError 是 URLError 的子类，专门用来处理 HTTP 请求错误，比如认证请求失败，包含以下三个属性：</p>

<ul>
  <li>code：返回 HTTP 响应的状态码，如404页面不存在等。</li>
  <li>reason：返回错误的原因。</li>
  <li>headers：返回 HTTP 响应头信息。</li>
</ul>

<p>应用举例：</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 返回401未授权错误
from urllib import request,error
try:
    response=request.urlopen('http://pythonscraping.com/pages/auth/login.php')
    print(response.getcode())
except error.HTTPError as e:
    print('1.错误原因：\n%s\n2.状态码：\n%s\n3.响应头信息：\n%s' %(e.reason, e.code, e.headers))
except error.URLError as e:
    print(e.reason)
</code></pre></div></div>

<h2 id="3-urllibparse-模块">3 urllib.parse 模块</h2>

<p>urllib.parse 模块定义了一个处理 url 的标准接口，用来实现 url 字符串的抽取、合并以及链接转换。该模块主要用到的函数如下。</p>

<h3 id="31-urllibparseurlparseurlstring-scheme-allow_fragmentstrue">3.1 urllib.parse.urlparse(urlstring, scheme=’’, allow_fragments=True)</h3>

<p>用于实现 url 字符串的识别和分段，可以分为六个字符串，分别是 scheme (协议)，netloc (域名)，path (路径)，params (参数)，query (查询条件)和 fragment (锚点)，其结构如下所示：“scheme://netloc/path;parameters?query#fragment”。实际上具体 url 某些字段可能会不存在，比如 “http://www.baidu.com” 只包含了协议和域名。</p>

<h4 id="311-urlparse-函数中参数定义">3.1.1 urlparse 函数中参数定义</h4>

<ul>
  <li>urlstring，待解析的 url 字符串。</li>
  <li>scheme，是默认的协议，比如 http 或者 https，url 字符串中如果不携带相关协议，可以通过 scheme 来指定，如果 url 中指定了相关协议则在 url 中生效。</li>
  <li>allow_fragments，是否忽略锚点，设置为 False 即 fragment 部分会被忽略，反之不会忽略。</li>
</ul>

<h4 id="312-urlparse-的返回类型">3.1.2 urlparse 的返回类型</h4>

<p>函数返回的是一个 urllib.parse.ParseResult 对象，获取解析出来的 url 六个字段。</p>

<h4 id="313-urlparse-应用举例">3.1.3 urlparse 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 解析并输出 url 中每个字段的字符串
import urllib
url = 'http://www.baidu.com/urllib.parse.html;python?kw=urllib.parse#module-urllib'
result = urllib.parse.urlparse(url)
print(result)
print(result.scheme, result.netloc, result.path, result.params, result.query, result.fragment, sep = '\n')
</code></pre></div></div>

<h3 id="32-urllibparseurlunparseparts">3.2 urllib.parse.urlunparse(parts)</h3>

<p>与 urlparse 相反，通过列表或者元祖的形式将分段的字符串组合成一个完整的 url 字符串。</p>

<h4 id="321-urlunparse-函数中参数定义">3.2.1 urlunparse 函数中参数定义</h4>

<ul>
  <li>parts，可以是列表或者元组。</li>
</ul>

<h4 id="322-urlunparse-的返回类型">3.2.2 urlunparse 的返回类型</h4>

<p>urlunparse 函数返回一个构造好的 url 字符串。</p>

<h4 id="323-应用举例">3.2.3 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 通过 data 列表或元组构造一个 url 并输出
import urllib
dataList = ['http', 'www.baidu.com', '/urllib.parse.html', 'python', 'kw=urllib.parse', 'modul-urllib'] # 六个字符串都必须填写，否则会出现 ValueError 错误，如果某一字符串不存在则填入空字符
dataTuple = ('http', 'www.baidu.com', '/urllib.parse.html', '', 'kw=urllib.parse', 'modul-urllib') # 六个字符串都必须填写，否则会出现 ValueError 错误，如果某一字符串不存在则填入空字符
urlList = urllib.parse.urlunparse(dataList)
urlTuple = urllib.parse.urlunparse(dataTuple)
print('1.urlList:%s\n2.urlTuple:%s' % (urlList, urlTuple))
</code></pre></div></div>

<h3 id="33-urllibparseurlspliturlstring-scheme-allow_fragmentstrue">3.3 urllib.parse.urlsplit(urlstring, scheme=’’, allow_fragments=True)</h3>

<p>与 urlparse 函数类似，但它只返回 url 字符串的5个字段，把 params 合并到 path 中。</p>

<h4 id="urlsplit-应用举例">urlsplit 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 解析并输出 url 中每个字段的字符串，params 会合并到 path 中。
import urllib
url = 'http://www.baidu.com/urllib.parse.html;python?kw=urllib.parse#modul-urllib'
result = urllib.parse.urlsplit(url)
print(result)
print(result.scheme, result.netloc, result.path, result.query, result.fragment, sep = '\n')
</code></pre></div></div>

<h3 id="34-urllibparseurlunsplitparts">3.4 urllib.parse.urlunsplit(parts)</h3>

<p>与 urlunparse 函数类似，它也是将 url 中各部分字段组合完整的 url 字符串的方法，唯一的区别是列表或元组的长度必须是5个，因为它把 params 省略了。</p>

<h4 id="urlunsplit-应用举例">urlunsplit 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 通过 data 列表或元组构造一个 url 并输出
import urllib
dataList = ['http', 'www.baidu.com', '/urllib.parse.html;python', 'kw=urllib.parse', 'modul-urllib'] # 五个字符串都必须填写，否则会出现 ValueError 错误，如果某一字符串不存在则填入空字符
dataTuple = ('http', 'www.baidu.com', '/urllib.parse.html;python', 'kw=urllib.parse', 'modul-urllib') # 五个字符串都必须填写，否则会出现 ValueError 错误，如果某一字符串不存在则填入空字符
urlList = urllib.parse.urlunsplit(dataList)
urlTuple = urllib.parse.urlunsplit(dataTuple)
print('1.urlList:%s\n2.urlTuple:%s' % (urlList, urlTuple))
</code></pre></div></div>

<h3 id="35-urllibparsequotestring-safe-encodingnone-errorsnone">3.5 urllib.parse.quote(string, safe=’/’, encoding=None, errors=None)</h3>

<p>使用 %xx 转义字符替换字符串中的特殊字符，比如汉字。字母、数字和‘_.-~’字符不会被替换。</p>

<h4 id="351-quote-函数中参数定义">3.5.1 quote 函数中参数定义</h4>

<ul>
  <li>string，可以是 str 字符串或 bytes 类型。</li>
  <li>safe，可选参数，默认是’/’，指明不应该被替换的附加 ASCII 字符。</li>
  <li>encoding 和 errors，可选参数，用来定义如何处理 non-ASCII 字符。一般默认设置编码方法为 encoding=’utf-8’，errors=’strict’，这意味着编码错误将引发 UnicodeError。如果 string 是 bytes 类型，不能设置 encoding 和 errors，否则将引发 TypeError。</li>
</ul>

<h4 id="352-quote-函数的返回类型">3.5.2 quote 函数的返回类型</h4>

<p>quote 函数返回一个编码后的字符串。</p>

<h4 id="353-应用举例">3.5.3 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 采用 quote 对 url 中的汉字进行编码，输出编码后的结果
import urllib
url = 'http://www.baidu.com/爬虫'
result = urllib.parse.quote(url)
print(result)
url = 'http://www.baidu.com/+爬虫'
result = urllib.parse.quote(url, '+') # 更改 safe 参数
print(result)
</code></pre></div></div>

<h3 id="36-urllibparseunquotestring-encodingutf-8-errorsreplace">3.6 urllib.parse.unquote(string, encoding=’utf-8’, errors=’replace’)</h3>

<p>与 quote 函数相反，把 %xx 转义字符替换成字符。</p>

<h4 id="361-unquote-函数的参数定义">3.6.1 unquote 函数的参数定义</h4>

<ul>
  <li>string，必须是 str 字符串。</li>
  <li>encoding 和 errors，可选参数，定义如何将 %xx 转义字符解码为 Unicode 字符。encoding 默认为 ‘utf-8’，errors 默认为 ‘replace’，表示无效的转义字符将会用占位符替换。</li>
</ul>

<h4 id="362-unquote-函数的返回类型">3.6.2 unquote 函数的返回类型</h4>

<p>unquote 函数返回一个解码后的字符串。</p>

<h4 id="363-应用举例">3.6.3 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 解码经过 quote 函数处理后的 url，输出解码后的结果。
import urllib
url = 'http://www.baidu.com/爬虫'
result = urllib.parse.quote(url)
print(result)
result = urllib.parse.unquote(url)
print(result)
</code></pre></div></div>

<h3 id="37-urllibparseurljoinbase-url-allow_fragmentstrue">3.7 urllib.parse.urljoin(base, url, allow_fragments=True)</h3>

<p>该函数用来将基本 url 与另一个 url 组合，更新基本 url 字符串。它会使用 url 对基本 url 中缺失的部分进行补充，比如 scheme (协议)、netloc (域名)和 path (路径)。即根据 url 字符串中带有的字段，对基本 url 中没有的字段进行补充，已存在的字段进行替换。</p>

<h4 id="371-urljoin-函数中参数定义">3.7.1 urljoin 函数中参数定义</h4>

<ul>
  <li>base，是一个基本 url。</li>
  <li>url，将 scheme (协议)、netloc (域名)或 path (路径)字段组合进基本 url 的 url。</li>
  <li>allow_fragments，是否忽略锚点，设置为 False 即 fragment 部分会被忽略，反之不会忽略。</li>
</ul>

<h4 id="372-urljoin-函数返回类型">3.7.2 urljoin 函数返回类型</h4>

<p>返回组合成功的 url 字符串。</p>

<h4 id="373-应用举例">3.7.3 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 基于 url 对 base_url 进行重新组合，并输出组合结果。
import urllib
base_url = 'http://www.baidu.com'
url = 'https://www.google.com/urllib.parse.html;python?kw=urllib.parse#module-urllib'
result = urllib.parse.urljoin(base_url,url,False)
print(result)
</code></pre></div></div>

<h3 id="38-urllibparseurlencodequery-doseqfalse-safe-encodingnone-errorsnone-quote_viaquote_plus">3.8 urllib.parse.urlencode(query, doseq=False, safe=’’, encoding=None, errors=None, quote_via=quote_plus)</h3>

<p>urlencode 函数可以将字典转化为 GET 请求中的 query (查询条件)，或者将字典转化为 POST 请求中需要上传的数据。</p>

<h4 id="381-urlencode-函数中参数定义">3.8.1 urlencode 函数中参数定义</h4>

<ul>
  <li>query，字典类型。</li>
  <li>doseq，允许字典中一个键对应多个值，编码成 query (查询条件)。</li>
  <li>safe、encoding 和 errors，这三个参数由 quote_via 指定。</li>
</ul>

<h4 id="382-urlencode-函数返回类型">3.8.2 urlencode 函数返回类型</h4>

<p>urlencode 函数返回 str 字符串。</p>

<h4 id="383-应用举例">3.8.3 应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 创建 GET 请求
import urllib
params = {'username':'xxx','password':'123'}
base_url='http://www.baidu.com'
url=base_url + '?' + urllib.parse.urlencode(params)
print(url)
params = {'username':['xxx', 'yyy'], 'password':'123'} # username 键对应多个值
base_url='http://www.baidu.com'
url=base_url + '?' + urllib.parse.urlencode(params) # doseq 设置为 False，会解析成乱码
print(url)
url=base_url + '?' + urllib.parse.urlencode(params, True) # doseq 设置为 True
print(url)
</code></pre></div></div>

<h2 id="4-urllibrobotparse-模块">4 urllib.robotparse 模块</h2>

<p>rebotparser 模块提供了一个 RobotFileParser 类，主要用来解析网站上发布的 robots.txt，然后根据解析内容判断爬虫是否有权限来爬取这个网页。</p>

<h3 id="41-robotstxt-文件">4.1 robots.txt 文件</h3>

<p>robots.txt，存放于网站根目录下，采用 ASCII 编码的文本文件，记录此网站中的哪些内容是不应被爬虫获取的，哪些是可以被爬虫获取的。</p>

<h4 id="robotstxt-文件内容举例">robots.txt 文件内容举例</h4>

<p>User-agent: *
Disallow: /
Allow: /public/</p>

<ul>
  <li>User-agent，爬虫的名称，将其设置为 * 代表协议对任何爬虫有效，如果设置为 Baiduspider 则代表协议仅对百度爬虫有效，要是有多条则对多个爬虫有效，至少需要指定一条。</li>
  <li>Disallow，网页中不允许抓取的目录，上述例子中设置的 / 代表不允许抓取所有的页面。</li>
  <li>Allow，一般和 Disallow 一起使用，用来排除单独的某些限制，上述例子中设置为 /public/ 表示所有页面不允许抓取，但可以抓取 public 目录。</li>
</ul>

<h3 id="42-urllibrobotparserrobotfileparserurl-类及其常用方法">4.2 urllib.robotparser.RobotFileParser(url=’’) 类及其常用方法</h3>

<ul>
  <li>set_url(url)，设置引用 robots.txt 文件的 url，如果在创建 RobotFileParser 对象时传入了 url，那么就不需要使用这个方法设置 url。</li>
  <li>read()，读取 robots.txt 文件并将其提供给解析器，不返回任何内容。</li>
  <li>parse(lines)，用来解析 robots.txt 某些行的内容，并安装语法规则来分析内容。</li>
  <li>can_fetch(useragent, url)，传入两个参数，用户代理以及要爬取的网站，返回的内容是该用户代理否可以抓取这个网站，结果为 True 或 False。</li>
</ul>

<h4 id="应用举例">应用举例</h4>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 使用两种爬虫代理分别查看是否可以对 'http://www.baidu.com' 网站进行爬取
from urllib.robotparser import RobotFileParser
rp = RobotFileParser()
rp.set_url("http://www.baidu.com/robots.txt")
rp.read()
print(rp.can_fetch('Baiduspider', 'http://www.baidu.com')) 
print(rp.can_fetch('*', 'http://www.baidu.com'))
</code></pre></div></div>

<h2 id="5-总结">5 总结</h2>

<p>本节给大家介绍了 Python 中 urllib 包的使用，为 Python 工程师对该包的使用提供了支撑，了解爬取网站所需的一些基本函数操作。</p>

<h2 id="参考资料">参考资料</h2>

<p>[1] https://docs.python.org/3/library/urllib.html</p>

<p>[2] https://www.cnblogs.com/zhangxinqi/p/9170312.html</p>

<blockquote>
  <p>示例代码：<a href="https://github.com/JustDoPython/python-100-day/tree/master/day-056-urllib">Python-100-days-day056</a></p>
</blockquote>


            <!-- <div>
   <p align="center">
     	  
         <img src="http://favorites.ren/assets/images/python.jpg" >
         <br/>
         微信扫描二维码，关注我的公众号
        

   </p>
   <p align="center" style="margin-top: 15px; font-size: 11px;color: #cc0000;">
       <strong>（转载本站文章请注明作者和出处 <a href="http://www.ityouknow.com">纯洁的微笑-ityouknow</a>）</strong>
   </p>
   <p align="center" style="margin-top: 15px; font-size: 16px;color: #337ab7;">
       <strong><a href="http://laughyouth.com/" target="_blank">点击了解：全网唯二以程序员为主题的漫画公众号</a></strong>
   </p>
</div> -->

            <!-- Comments -->
            <div class="comment">
             

  
    <a href="#" class="show_disqus_comment" onclick="return false;">Show Disqus Comments</a>
    <div id="disqus_thread"></div>
    <script>
    var disqus_config = function () {
        this.page.url = 'https://panshuai1121.github.io/python/2019/11/12/python-spider-Urllib-056.html';
        this.page.identifier = '/python/2019/11/12/python-spider-Urllib-056.html';
        this.page.title = '第56天：urllib 包基本使用';
    };
    var disqus_loaded = false;
    $(function() {
        $('.show_disqus_comment').on('click', function() { // DON'T EDIT BELOW THIS LINE
            $(this).html('加载中...');
            var that = this;
            if (!disqus_loaded) {
                var d = document, s = d.createElement('script');

                s.type = 'text/javascript';
                s.async = true;
                var shortname = 'panshuai1121';

                s.src = '//' + shortname + '.disqus.com/embed.js';

                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);

                disqus_loaded = true;
            }
            $(that).remove();
        })
    })
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
  

  
        <div id="gitalk-container"></div>
        <script src="/assets/js/gitalk.min.js"></script>
        <script>
        var gitalk = new Gitalk({
            id: '/python/2019/11/12/python-spider-Urllib-056.html',
            clientID: '01c69b4bdbdbc141e10d',
            clientSecret: '287c9fc8219a6ceba7428bbd9f3aa0e123e193fb',
            repo: 'blog-comments',
            owner: 'panshuai1121',
            admin: ['panshuai1121'],
            labels: ['gitment'],
            perPage: 50,
        })
        gitalk.render('gitalk-container')
        </script>
  


            </div>
        </div>

        <div class="col-md-3">
            <h3>Post Directory</h3>
<div id="post-directory-module">
<section class="post-directory">
    <!-- Links that trigger the jumping -->
    <!-- Added by javascript below -->
    <dl></dl>
</section>
</div>

<script type="text/javascript">

    $(document).ready(function(){
        $( "article h2" ).each(function( index ) {
            $(".post-directory dl").append("<dt><a class=\"jumper\" hre=#" +
                    $(this).attr("id")
                    + ">"
                    + $(this).text()
                    + "</a></dt>");

            var children = $(this).nextUntil("h2", "h3")

            children.each(function( index ) {
                $(".post-directory dl").append("<dd><a class=\"jumper\" hre=#" +
                        $(this).attr("id")
                        + ">"
                        + "&nbsp;&nbsp;- " + $(this).text()
                        + "</a></dd>");
            });
        });

        var fixmeTop = $('#post-directory-module').offset().top - 100;       // get initial position of the element

        $(window).scroll(function() {                  // assign scroll event listener

            var currentScroll = $(window).scrollTop(); // get current position

            if (currentScroll >= fixmeTop) {           // apply position: fixed if you
                $('#post-directory-module').css({      // scroll to that element or below it
                    top: '100px',
                    position: 'fixed',
                    width: 'inherit'
                });
            } else {                                   // apply position: static
                $('#post-directory-module').css({      // if you scroll above it
                    position: 'inherit',
                    width: 'inherit'
                });
            }

        });

        $("a.jumper").on("click", function( e ) {

            e.preventDefault();

            $("body, html").animate({
                scrollTop: ($( $(this).attr('hre') ).offset().top - 100)
            }, 600);

        });
    });

</script>
        </div>
        

    </div>
     <!-- <div class="asb-post-01">
        <div class="mask"></div>
            <div class="info">
                <div>扫码关注公众号：<span style="color: #E9405A; font-weight: bold;">纯洁的微笑</span></div>
            <div>
            <span>发送 </span><span class="token" style="color: #e9415a; font-weight: bold; font-size: 17px; margin-bottom: 45px;">290992</span>
            <div>
                即可<span style="color: #e9415a; font-weight: bold;">立即永久</span>解锁本站全部文章
            </div>
            <img class="code-img" style="width: 300px;display:unset" src="http://favorites.ren/assets/images/keeppuresmile.jpg">
        </div>
    </div> -->
</article>

        </div>

    
<footer class="container">
    <div class="site-footer">
       <!--  <div class="site-footer-icons">
            <a target="_blank" href="https://www.zhihu.com/people/ityouknow">
               知乎
            </a>
            <a target="_blank" href="http://weibo.com/ityouknow">
               微博
            </a>
            <a target="_blank" href="https://github.com/ityouknow">
                GitHub
            </a>
        </div> -->
          <!-- <div class="card text-center">
            <ul class="list-inline" style="margin-left: 0;">
               <li>
                <a target="_blank" href="https://github.com/panshuai1121">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a target="_blank" href="https://www.zhihu.com/people/ityouknow">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa  fa-stack-1x fa-inverse">知</i>
                  </span>
                </a>
              </li>
                  <li>
                <a target="_blank" href="https://weibo.com/ityouknow">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          </ul>
        </div> -->
        <div class="site-footer-links mobile-hidden">
            
            <a href="/payment.html" title="Pay" target="_self">Pay</a>
            
            <a href="/fastdfs.html" title="FastDFS" target="_blank">FastDFS</a>
            
            <a href="/mongodb.html" title="MongoDB" target="_blank">MongoDB</a>
            
            <a href="/docker.html" title="Docker" target="_blank">Docker</a>
            
            <a href="/open-source.html" title="Code" target="_blank">Code</a>
            
            <a href="/gitchat.html" title="Chat" target="_blank">Chat</a>
            
            <a href="/redis.html" title="redis" target="_blank">redis</a>
            
        </div>
        <div class="site-footer-icons">
               <a href="http://beian.miit.gov.cn" >京ICP备15067287号</a>
        </div>
        <div class="scrolltop">
            <a href="javascript:window.scrollTo(0,0)" >TOP</a>
        </div>
        <div class="rss">
            <a href="/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a>
            Power by <a href="https://github.com/DONGChuan/Yummy-Jekyll">Yummy Jekyll</a>
        </div>
    </div>
    <!-- Third-Party JS -->
    <script type="text/javascript" src="/bower_components/geopattern/js/geopattern.min.js"></script>
    <!-- My JS -->
    <script type="text/javascript" src="/assets/js/script.js"></script>
    
    
     <!-- Cnzz Analytics -->
       <!-- <div style="display:none">
         <script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260945749'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1260945749' type='text/javascript'%3E%3C/script%3E"));</script>
       </div> -->
     <!-- Cnzz Analytics -->
</footer>


    </body>

</html>
