I"wj<p>我们本身是一家互联网金融公司，公司的主流业务就是p2p，因为各种原因吧，15年底启动建设众筹平台。考虑到前期开发过程中的一些弊端和架构经验，本次架构引用了dubbo做soa服务的治理，web容器nginx+tomcat，后端语言采用java,框架选择spring+mybaits,前端模板引擎使用的是btl,app采用原生+h5的模式。这个架构可以参考我之前写的文章<a href="http://www.ityouknow.com/arch/2017/01/10/ten-billion-architecture-history.html">从零到百亿互联网金融架构发展史</a>中的第三代系统架构,之前的文章主要介绍了架构的变迁，本篇文章主要介绍在第三代平台中遇到的问题以及解决方法。</p>

<p>首先介绍一下众筹系统的部署架构（如下图），网站和app请求都是首先到最前端的nginx,如果只是静态内容的访问nginx直接处理后返回；动态请求分别转发到后端的tomcat前端服务层，前端服务层只关注页面端业务逻辑不涉及数据库的操作，如果只是页面框架渲染以及不涉及数据库的请求，在前端服务层直接处理返回；如果涉及到数据库操作或者核心业务逻辑，前端服务层通过dubbo调用后端的接入层服务或者核心层服务。</p>

<p><img src="http://favorites.ren/assets/images/2017/optimize/zhongchou.jpg" alt="" /></p>

<p>上线在生产测试期间，发现tomcat过一段时间就会莫名奇妙的down掉，特别是后端的tomcat down掉的频率比较高。后端的tomcat down掉之后对前端的页面展示没有影响，会影响后端的交易。</p>

<h2 id="jvm参数配置">jvm参数配置</h2>

<p>查看tomcat业务日志，报错如下：</p>

<div class="language-properties highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">2016-04-14</span> <span class="py">12</span><span class="p">:</span><span class="s">01:55,025 - org.jboss.netty.channel.DefaultChannelPipeline -59679839 [New I/O worker #29] WARN  null -  [DUBBO] An exception was thrown by a user handler while handling an exception event ([id: 0x5f980c11, /xxx:55386 =&gt; /xxx:6666] EXCEPTION: com.alibaba.dubbo.remoting.ExecutionException: class com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler error when process received event .), dubbo version: 2.8.4, current host: xxx</span>
<span class="py">com.alibaba.dubbo.remoting.ExecutionException</span><span class="p">:</span> <span class="s">class com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler error when process caught event .</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler.caught(</span><span class="py">AllChannelHandler.java</span><span class="p">:</span><span class="s">67)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.AbstractChannelHandlerDelegate.caught(</span><span class="py">AbstractChannelHandlerDelegate.java</span><span class="p">:</span><span class="s">44)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.AbstractChannelHandlerDelegate.caught(</span><span class="py">AbstractChannelHandlerDelegate.java</span><span class="p">:</span><span class="s">44)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.AbstractPeer.caught(</span><span class="py">AbstractPeer.java</span><span class="p">:</span><span class="s">127)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.netty.NettyHandler.exceptionCaught(</span><span class="py">NettyHandler.java</span><span class="p">:</span><span class="s">112)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.netty.NettyCodecAdapter$InternalDecoder.exceptionCaught(</span><span class="py">NettyCodecAdapter.java</span><span class="p">:</span><span class="s">165)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireExceptionCaught(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">525)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(</span><span class="py">AbstractChannelSink.java</span><span class="p">:</span><span class="s">48)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireMessageReceived(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">296)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.netty.NettyCodecAdapter$InternalDecoder.messageReceived(</span><span class="py">NettyCodecAdapter.java</span><span class="p">:</span><span class="s">148)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireMessageReceived(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">268)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireMessageReceived(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">255)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.NioWorker.read(</span><span class="py">NioWorker.java</span><span class="p">:</span><span class="s">88)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(</span><span class="py">AbstractNioWorker.java</span><span class="p">:</span><span class="s">109)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(</span><span class="py">AbstractNioSelector.java</span><span class="p">:</span><span class="s">312)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(</span><span class="py">AbstractNioWorker.java</span><span class="p">:</span><span class="s">90)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.NioWorker.run(</span><span class="py">NioWorker.java</span><span class="p">:</span><span class="s">178)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor.runWorker(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">1145)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor$Worker.run(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">615)</span>
    <span class="err">at</span> <span class="err">java.lang.Thread.run(</span><span class="py">Thread.java</span><span class="p">:</span><span class="s">745)</span>
<span class="err">Caused</span> <span class="py">by</span><span class="p">:</span> <span class="s">java.lang.OutOfMemoryError: unable to create new native thread</span>
    <span class="err">at</span> <span class="err">java.lang.Thread.start0(Native</span> <span class="err">Method)</span>
    <span class="err">at</span> <span class="err">java.lang.Thread.start(</span><span class="py">Thread.java</span><span class="p">:</span><span class="s">714)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor.addWorker(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">949)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor.execute(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">1360)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler.caught(</span><span class="py">AllChannelHandler.java</span><span class="p">:</span><span class="s">65)</span>
    <span class="err">...</span> <span class="err">19</span> <span class="err">more</span>
</code></pre></div></div>

<p>查看output日志，发现其中有这么一句。</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SEVERE: The web application [/xxx] appears to have started a thread named [DubboResponseTimeoutScanTimer] but has failed to stop it. This is very likely to create a memory leak.
</code></pre></div></div>

<p>根据日志提示貌似有内存泄露，以前确实还没有碰到过这个错误，一片迷茫。重新启动后，先用命令<code class="highlighter-rouge">jstat -gc xxx 1000 30</code>查看java 进程的gc情况，发现在30秒的世界内minor gc了n次，随怀疑年轻代内存配置少了，查看个区域内存的配置参数如下：</p>

<div class="language-properties highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">-Xms10g</span> <span class="err">-Xmx10g</span> <span class="py">-XX</span><span class="p">:</span><span class="s">PermSize=1g -XX:MaxPermSize=2g -Xshare:off -Xmn1024m</span>
</code></pre></div></div>

<p>按照年轻代为堆内存为百分之三的原则修改为<code class="highlighter-rouge">-Xmn4g</code>，重新启动观察之后mimor gc的频率确实有所下降，测试大约过了3小时候之后又反馈tomcat down掉了，继续分析启动参数配置的时候发现了这么一句<code class="highlighter-rouge">-XX:-+DisableExplicitGC</code>,显示的禁止了<code class="highlighter-rouge">System.gc()</code>,但是使用了java.nio的大量框架中使用<code class="highlighter-rouge">System.gc()</code>来执行gc期通过full gc来强迫已经无用的DirectByteBuffer对象释放掉它们关联的native memory,如果禁用会导致OOM,随即怀疑是否是这个参数引发的问题，在启动参数中去掉它。</p>

<p>为了防止再次出现异常的时候能更加详细的分析堆内存的使用情况，在启动参数中添加了<code class="highlighter-rouge">-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/logs/java/</code>，当tomcat down的时候让输出堆内存文件，一边也启动jvisualvm工具来实时的监控内存各个线程的使用情况。</p>

<h2 id="数据库连接池">数据库连接池</h2>

<p>继续使用压测工具来压测，在压测的过程中发现名为<code class="highlighter-rouge">com.mchange.v2.resourcepool.ssync.ThreadPoolAsynchronousRunner$PoolThred-#xxx</code>的线程不断的增长，并且后台tomcat报错如下：</p>

<div class="language-properties highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">2016-04-13</span> <span class="py">16</span><span class="p">:</span><span class="s">55:15,175 - com.alibaba.dubbo.common.threadpool.support.AbortPolicyWithReport -83649035 [New I/O worker #27] WARN  -  [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-xxx:6666, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 692 (completed: 492), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://xxx:6666!, dubbo version: 2.8.4, current host: xxx</span>
<span class="err">2016-04-13</span> <span class="py">16</span><span class="p">:</span><span class="s">55:15,176 - com.alibaba.dubbo.common.threadpool.support.AbortPolicyWithReport -83649036 [New I/O worker #27] WARN  -  [DUBBO] Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-xxx:6666, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 692 (completed: 492), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://xxx:6666!, dubbo version: 2.8.4, current host: xxx</span>
<span class="err">2016-04-13</span> <span class="py">16</span><span class="p">:</span><span class="s">55:15,177 - org.jboss.netty.channel.DefaultChannelPipeline -83649037 [New I/O worker #27] WARN  -  [DUBBO] An exception was thrown by a user handler while handling an exception event ([id: 0x2f345d45, /192.168.57.20:36475 =&gt; /xxx:6666] EXCEPTION: com.alibaba.dubbo.remoting.ExecutionException: class com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler error when process received event .), dubbo version: 2.8.4, current host: xxx</span>
<span class="py">com.alibaba.dubbo.remoting.ExecutionException</span><span class="p">:</span> <span class="s">class com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler error when process caught event .</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler.caught(</span><span class="py">AllChannelHandler.java</span><span class="p">:</span><span class="s">67)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.AbstractChannelHandlerDelegate.caught(</span><span class="py">AbstractChannelHandlerDelegate.java</span><span class="p">:</span><span class="s">44)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.AbstractChannelHandlerDelegate.caught(</span><span class="py">AbstractChannelHandlerDelegate.java</span><span class="p">:</span><span class="s">44)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.AbstractPeer.caught(</span><span class="py">AbstractPeer.java</span><span class="p">:</span><span class="s">127)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.netty.NettyHandler.exceptionCaught(</span><span class="py">NettyHandler.java</span><span class="p">:</span><span class="s">112)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.netty.NettyCodecAdapter$InternalDecoder.exceptionCaught(</span><span class="py">NettyCodecAdapter.java</span><span class="p">:</span><span class="s">165)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireExceptionCaught(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">525)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.AbstractChannelSink.exceptionCaught(</span><span class="py">AbstractChannelSink.java</span><span class="p">:</span><span class="s">48)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireMessageReceived(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">296)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.netty.NettyCodecAdapter$InternalDecoder.messageReceived(</span><span class="py">NettyCodecAdapter.java</span><span class="p">:</span><span class="s">148)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireMessageReceived(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">268)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.Channels.fireMessageReceived(</span><span class="py">Channels.java</span><span class="p">:</span><span class="s">255)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.NioWorker.read(</span><span class="py">NioWorker.java</span><span class="p">:</span><span class="s">88)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(</span><span class="py">AbstractNioWorker.java</span><span class="p">:</span><span class="s">109)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(</span><span class="py">AbstractNioSelector.java</span><span class="p">:</span><span class="s">312)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(</span><span class="py">AbstractNioWorker.java</span><span class="p">:</span><span class="s">90)</span>
    <span class="err">at</span> <span class="err">org.jboss.netty.channel.socket.nio.NioWorker.run(</span><span class="py">NioWorker.java</span><span class="p">:</span><span class="s">178)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor.runWorker(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">1145)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor$Worker.run(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">615)</span>
    <span class="err">at</span> <span class="err">java.lang.Thread.run(</span><span class="py">Thread.java</span><span class="p">:</span><span class="s">745)</span>
<span class="err">Caused</span> <span class="py">by</span><span class="p">:</span> <span class="s">java.util.concurrent.RejectedExecutionException: Thread pool is EXHAUSTED! Thread Name: DubboServerHandler-xxx:6666, Pool Size: 200 (active: 200, core: 200, max: 200, largest: 200), Task: 692 (completed: 492), Executor status:(isShutdown:false, isTerminated:false, isTerminating:false), in dubbo://xxx:6666!</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.common.threadpool.support.AbortPolicyWithReport.rejectedExecution(</span><span class="py">AbortPolicyWithReport.java</span><span class="p">:</span><span class="s">53)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor.reject(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">821)</span>
    <span class="err">at</span> <span class="err">java.util.concurrent.ThreadPoolExecutor.execute(</span><span class="py">ThreadPoolExecutor.java</span><span class="p">:</span><span class="s">1372)</span>
    <span class="err">at</span> <span class="err">com.alibaba.dubbo.remoting.transport.dispatcher.all.AllChannelHandler.caught(</span><span class="py">AllChannelHandler.java</span><span class="p">:</span><span class="s">65)</span>
    <span class="err">...</span> <span class="err">19</span> <span class="err">more</span>

</code></pre></div></div>

<p>根据这些信息随怀疑数据库连接池有问题，为了更好的监控连接池的使用，因此前期使用c3p0也会出现的一些问题，所以我们决定将数据库连接池替换成druid，已经在别的项目中使用测试过，因此非常快速的更换投产。投产后继续用压测工具来测试，根据druid的后台监控页面发现（项目地址/druid/index.html），每次前端掉用一次数据库连接就加一次,执行完成之后数据库连接并没有释放。如下图红色区域，我们将数据库连接池调整成1000,不一会就占满了。</p>

<p><img src="http://favorites.ren/assets/images/2017/optimize/druid.jpg" alt="" /></p>

<p>根据这些信息判断出，数据库执行sql后肯定没有释放数据库连接，导致数据库连接池用满后，后续的线程无法执行，检查代码之后发现果然有问题,请看下方代码，我们最先使用的是SqlSessionFactory，如果使用SqlSessionFactory,在执行完sql后必须要执行<code class="highlighter-rouge">session.close()</code>来关闭连接，才会被连接池重新回收。</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SessionFactory</span> <span class="o">{</span>
    <span class="nd">@Resource</span>
    <span class="kd">private</span> <span class="nc">SqlSessionFactory</span> <span class="n">coreSqlSessionFactory</span><span class="o">;</span>
    <span class="kd">protected</span> <span class="nc">SqlSession</span> <span class="nf">getSession</span><span class="o">()</span> <span class="o">{</span>
		<span class="k">return</span> <span class="n">coreSqlSessionFactory</span><span class="o">.</span><span class="na">openSession</span><span class="o">();</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">BaseDao</span> <span class="kd">extends</span> <span class="nc">SessionFactory</span><span class="o">{</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">add</span><span class="o">(</span><span class="nc">Entity</span> <span class="n">entity</span><span class="o">)</span> <span class="o">{</span>
    	<span class="k">this</span><span class="o">.</span><span class="na">getSession</span><span class="o">().</span><span class="na">update</span><span class="o">(</span><span class="n">entity</span><span class="o">.</span><span class="na">getClass</span><span class="o">().</span><span class="na">getSimpleName</span><span class="o">()+</span><span class="s">"."</span><span class="o">+</span><span class="nc">Thread</span><span class="o">.</span><span class="na">currentThread</span><span class="o">().</span><span class="na">getStackTrace</span><span class="o">()[</span><span class="mi">2</span><span class="o">].</span><span class="na">getMethodName</span><span class="o">(),</span> <span class="n">entity</span><span class="o">);</span>
    <span class="o">}</span>
<span class="o">}</span>    
</code></pre></div></div>

<p>但是使用SqlSessionTemplate却不用手动执行代码来关闭session,因此我们把上面SessionFactory类中的代码改成SqlSessionTemplate（如下），此问题便解决了。</p>

<div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">public</span> <span class="kd">class</span> <span class="nc">SessionFactory</span> <span class="o">{</span>
    <span class="nd">@Resource</span>  
    <span class="kd">public</span> <span class="nc">SqlSessionTemplate</span> <span class="n">coreSqlSession</span><span class="o">;</span>
    <span class="kd">protected</span> <span class="nc">SqlSessionTemplate</span> <span class="nf">getSession</span><span class="o">()</span> <span class="o">{</span>
    	<span class="k">return</span> <span class="n">coreSqlSession</span><span class="o">;</span>
    <span class="o">}</span>
<span class="o">}</span>  
</code></pre></div></div>

<h2 id="诡异的脚本">诡异的脚本</h2>

<p>做完上面的优化之后，我们感觉问题应该解决了，但过了一段时间后tomcat又诡异的挂了，继续分析gc情况，分阶段使用<code class="highlighter-rouge">jmap -dump:live,format=b,file=dump.hprof xxx</code>命令生成堆转储快照来对比堆内存使用情况，监控线程使用情况，均发现没有问题。这个问题困扰了我们好几天，每天都监控这端口，一但发现tomcat down之后马上通知运营人员重启。一方面我们也查阅了各种资料，到网上查找各种tomcat自动down的原因，一一在我们服务器进行了测试、修复均不起作用。</p>

<p>终于在google各种tomcat down原因的时候发现了这么一篇文章<a href="http://ifeve.com/why-kill-2-cannot-stop-tomcat/">Tomcat进程意外退出的问题分析</a>,立刻想起了我们最近使用的一个脚本来，因为我们的tomcat禁止了通过bat文件来关闭，因此为了启动方便我们写了一个脚本文件，方便通过脚本来启动、停止、重启tomcat文件，这是这个脚本导致tomcat down的原因，不不，不叫原因叫元凶！脚本内容如下：</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/sh</span>
<span class="c"># eg: tomcat.sh start xxx</span>
<span class="c">#</span>
<span class="nv">proc_dir</span><span class="o">=</span><span class="s2">"/usr/local/xxx/tomcat-zc-web/bin"</span>
<span class="nv">proc_name</span><span class="o">=</span><span class="nv">$2</span>
<span class="k">if</span> <span class="o">[</span> x<span class="nv">$proc_name</span> <span class="o">!=</span> x <span class="o">]</span>
<span class="k">then
	</span><span class="nv">proc_dir</span><span class="o">=</span><span class="k">${</span><span class="nv">proc_dir</span><span class="p">//xxx/</span><span class="nv">$proc_name</span><span class="k">}</span>
<span class="k">fi</span>
<span class="c">#echo $proc_dir</span>
<span class="k">function </span>stop <span class="o">()</span> <span class="o">{</span>
  <span class="nb">kill</span> <span class="nt">-9</span> <span class="sb">`</span>ps <span class="nt">-ef</span> |grep <span class="nv">$proc_dir</span> |grep <span class="nt">-v</span> <span class="nb">grep</span>|awk <span class="s1">'{print $2}'</span><span class="sb">`</span>
<span class="o">}</span>

<span class="k">function </span>start <span class="o">()</span> <span class="o">{</span>
  <span class="nb">cd</span> <span class="nv">$proc_dir</span>
  ./startup.sh
  <span class="nb">tail</span> <span class="nt">-300f</span> /usr/local/logs/tomcat-business/<span class="nv">$proc_name</span>.log
<span class="o">}</span>

<span class="k">case</span> <span class="nv">$1</span> <span class="k">in 
  </span>start<span class="p">)</span>
	start<span class="p">;;</span>
  stop<span class="p">)</span>
	stop<span class="p">;;</span>
  restart<span class="p">)</span>
	stop
	start<span class="p">;;</span>
<span class="k">esac</span>
</code></pre></div></div>

<p>就是因为<code class="highlighter-rouge">tail -300f /usr/local/logs/tomcat-business/$proc_name.log</code>这一句导致的问题，在别的项目使用的时候其实是没有这一句的，一般在使用的步骤是：</p>

<ul>
  <li>1 执行<code class="highlighter-rouge">tomcat.sh start xxx</code>启动tomcat,</li>
  <li>2 执行<code class="highlighter-rouge">tail -300f /usr/local/logs/tomcat-business/xxx.log</code> 查看启动日志是否成功。</li>
</ul>

<p>在这次投产的时候为了省一步操作，就将执行查看日志的命令，直接加在了启动命令的后面，当执行<code class="highlighter-rouge">tomcat.sh start xxx</code>这个命令的时候，即启动的tomcat，也自动会打印出tomcat的日志，那时候的想法非常好。</p>

<p>原因是，使用脚本命令启动后因为使用了<code class="highlighter-rouge">tail -300f xxx</code> 命令，tomcat的进程会成为shell脚本的子进程，这样的话，如果shell脚本停止的话，系统会自动杀掉tomcat进程导致tomcat down掉，在我们的脚本中去掉这条命令tomcat就正常了，更深层次的原因参考<a href="http://ifeve.com/why-kill-2-cannot-stop-tomcat/">Tomcat进程意外退出的问题分析</a>这篇文章，文章的内容还是分析的比较透彻，最后感觉阿里的技术真的很牛X，这篇文章也是出自于阿里的员工。</p>

<blockquote>
  <p>经历这么些波折，后续的tomcat服务终于稳定了下来</p>
</blockquote>

<hr />

<p><strong>作者：纯洁的微笑</strong><br />
<strong>出处：<a href="http://www.ityouknow.com">www.ityouknow.com</a></strong>  <br />
<strong>版权归作者所有，转载请注明出处</strong></p>
:ET